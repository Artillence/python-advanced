{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9XvMceMl6J1",
        "outputId": "62f141b7-a6e4-4cb0-b208-d2032ca2821a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Jul 30 21:18:49 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   57C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WqaywebcktKY",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "0b6e5fcf-cf51-4473-a857-073a3fc8965a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cupy-cuda12x in /usr/local/lib/python3.10/dist-packages (12.2.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (0.60.0)\n",
            "Requirement already satisfied: numpy<1.27,>=1.20 in /usr/local/lib/python3.10/dist-packages (from cupy-cuda12x) (1.26.4)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.10/dist-packages (from cupy-cuda12x) (0.8.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba) (0.43.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://pypi.nvidia.com\n",
            "Requirement already satisfied: cudf-cu12 in /usr/local/lib/python3.10/dist-packages (24.4.1)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from cudf-cu12) (5.4.0)\n",
            "Requirement already satisfied: cuda-python<13.0a0,>=12.0 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12) (12.2.1)\n",
            "Requirement already satisfied: cupy-cuda12x>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12) (12.2.0)\n",
            "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12) (2024.6.1)\n",
            "Requirement already satisfied: numba>=0.57 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12) (0.60.0)\n",
            "Requirement already satisfied: numpy<2.0a0,>=1.23 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12) (1.26.4)\n",
            "Requirement already satisfied: nvtx>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12) (0.2.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from cudf-cu12) (24.1)\n",
            "Requirement already satisfied: pandas<2.2.2dev0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12) (2.1.4)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12) (3.20.3)\n",
            "Requirement already satisfied: pynvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12) (0.3.0)\n",
            "Requirement already satisfied: pyarrow<15.0.0a0,>=14.0.1 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12) (14.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from cudf-cu12) (13.7.1)\n",
            "Requirement already satisfied: rmm-cu12==24.4.* in /usr/local/lib/python3.10/dist-packages (from cudf-cu12) (24.4.0)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12) (4.12.2)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from cuda-python<13.0a0,>=12.0->cudf-cu12) (3.0.10)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.10/dist-packages (from cupy-cuda12x>=12.0.0->cudf-cu12) (0.8.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.57->cudf-cu12) (0.43.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.2dev0,>=2.0->cudf-cu12) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.2dev0,>=2.0->cudf-cu12) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.2dev0,>=2.0->cudf-cu12) (2024.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->cudf-cu12) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->cudf-cu12) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->cudf-cu12) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<2.2.2dev0,>=2.0->cudf-cu12) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install cupy-cuda12x numba\n",
        "!pip install --extra-index-url=https://pypi.nvidia.com cudf-cu12"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSL5Ywj9sR2l"
      },
      "source": [
        "# Cupy as a drop-in replacement for numpy\n",
        "\n",
        "In this example, we demonstrate how to use [CuPy](https://github.com/cupy/cupy), a GPU array library that leverages NVIDIA CUDA to provide a familiar interface for NumPy users. CuPy enables the acceleration of array operations by utilizing the parallel computing power of GPUs. Here, we showcase the process of creating a random array on the GPU, performing elementwise operations on it, and then transferring the results back to the host (CPU)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WVLPWtvkNmU",
        "outputId": "cf490fc2-347d-4951-91b4-8c6ef2e3fe87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.79131525 0.7764646  0.13682646 0.72502146 0.44126537 0.6260933\n",
            " 0.07038901 0.51977258 0.48913717 0.22888138]\n"
          ]
        }
      ],
      "source": [
        "import numpy as cp\n",
        "# import cupy as cp\n",
        "\n",
        "# Create a random array on the GPU\n",
        "x = cp.random.rand(1000000)\n",
        "\n",
        "# Perform elementwise operations\n",
        "y = cp.sin(x)\n",
        "\n",
        "# Transfer data back to the host (CPU)\n",
        "print(y[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQj0iSv0s-iN"
      },
      "source": [
        "# Numba JIT compiler to translate Python code into machine code.\n",
        "\n",
        "In this example, we are using the [Numba](https://github.com/numba/numba?tab=readme-ov-file) library to optimize a Python function for summing all elements in a 1D NumPy array. Numba is a just-in-time compiler that translates a subset of Python and NumPy code into fast machine code. By using the `@jit` decorator with the `nopython=True` option, we instruct Numba to compile the function to machine code, resulting in significant speed improvements for numerical operations. The code demonstrates how to apply this technique to a simple function that iterates through a 2D array and calculates the sum of its elements."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_MqBdHZgmCj",
        "outputId": "424e1ec2-83d5-49d6-d908-001fdc901c22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4941.595576842995\n"
          ]
        }
      ],
      "source": [
        "from numba import jit\n",
        "import numpy as np\n",
        "\n",
        "@jit(nopython=True)\n",
        "def sum_1d_array(arr):\n",
        "    result = 0.0\n",
        "    for value in arr:\n",
        "        result += value\n",
        "    return result\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "arr = np.random.rand(10000)\n",
        "result = sum_1d_array(arr)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7I_Uykp6gmCk"
      },
      "source": [
        "# Exercise: sum 2D array\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fFIkyINcgmCk"
      },
      "outputs": [],
      "source": [
        "from numba import jit\n",
        "import numpy as np\n",
        "\n",
        "# Implement the 2D sum function.\n",
        "# Note: you can use arr.shape, which returns a tuple to determine the size of the ndarray.\n",
        "@jit(nopython=True)\n",
        "def sum_2d_array(arr):\n",
        "    # ...\n",
        "\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "arr = np.random.rand(1000, 1000)\n",
        "result = sum_2d_array(arr)\n",
        "print(result)\n",
        "\n",
        "# Expected result: 500334.4861757136"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktt2McrskhGW",
        "jupyter": {
          "source_hidden": true
        },
        "outputId": "ce99b92a-cfce-4205-83d2-f043a14c191e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "500334.4861757136\n"
          ]
        }
      ],
      "source": [
        "# Solution\n",
        "\n",
        "from numba import jit\n",
        "import numpy as np\n",
        "\n",
        "@jit(nopython=True)\n",
        "def sum_2d_array(arr):\n",
        "    m, n = arr.shape\n",
        "    result = 0.0\n",
        "    for i in range(m):\n",
        "        for j in range(n):\n",
        "            result += arr[i, j]\n",
        "    return result\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "arr = np.random.rand(1000, 1000)\n",
        "result = sum_2d_array(arr)\n",
        "print(result)\n",
        "\n",
        "# Expected result: 500334.4861757136"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Iavn0jJgmCl",
        "outputId": "28ac8391-8496-4be2-90fe-e251cddd9aa4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numba execution time: 0.001617431640625 seconds\n",
            "Pure Python execution time: 0.18297934532165527 seconds\n"
          ]
        }
      ],
      "source": [
        "def sum_2d_array_pure_python(arr):\n",
        "    m, n = arr.shape\n",
        "    result = 0.0\n",
        "    for i in range(m):\n",
        "        for j in range(n):\n",
        "            result += arr[i, j]\n",
        "    return result\n",
        "\n",
        "import time\n",
        "\n",
        "# Timing the numba function\n",
        "start_time = time.time()\n",
        "result_numba = sum_2d_array(arr)\n",
        "end_time = time.time()\n",
        "print(f\"Numba execution time: {end_time - start_time} seconds\")\n",
        "\n",
        "# Timing the pure Python function\n",
        "start_time = time.time()\n",
        "result_pure_python = sum_2d_array_pure_python(arr)\n",
        "end_time = time.time()\n",
        "print(f\"Pure Python execution time: {end_time - start_time} seconds\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqzV5NAkuB9F"
      },
      "source": [
        "# Example: Computing Pairwise Distances on the GPU\n",
        "\n",
        "In this example, we'll explore how to compute the pairwise distance matrix of a given input matrix using GPU acceleration. The implementation leverages the numba library to offload computations to the GPU, significantly speeding up the process for large datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Etygc__mljm",
        "outputId": "61ab8885-e4e2-44c8-a7da-65e27f69be54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Matrix:\n",
            " [[0. 1.]\n",
            " [1. 0.]\n",
            " [2. 2.]]\n",
            "Pairwise Distance Matrix:\n",
            " [[0.        1.4142135 2.236068 ]\n",
            " [1.4142135 0.        2.236068 ]\n",
            " [2.236068  2.236068  0.       ]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the simplified gpu_dist_matrix function\n",
        "import math\n",
        "from numba import cuda\n",
        "\n",
        "def gpu_dist_matrix(mat, USE_64=True):\n",
        "    \"\"\"Compute distance between each pair of the input matrix using GPU.\"\"\"\n",
        "\n",
        "    np_type = np.float64 if USE_64 else np.float32\n",
        "\n",
        "    @cuda.jit\n",
        "    def distance_matrix(mat, out):\n",
        "        i, j = cuda.grid(2)\n",
        "        if i < mat.shape[0] and j < mat.shape[0]:\n",
        "            d = 0.0\n",
        "            for k in range(mat.shape[1]):\n",
        "                tmp = mat[i, k] - mat[j, k]\n",
        "                d += tmp * tmp\n",
        "            out[i, j] = math.sqrt(d)\n",
        "\n",
        "    rows = mat.shape[0]\n",
        "    block_dim = (16, 16)\n",
        "    grid_dim = ((rows + block_dim[0] - 1) // block_dim[0], (rows + block_dim[1] - 1) // block_dim[1])\n",
        "\n",
        "    mat_device = cuda.to_device(np.asarray(mat, dtype=np_type))\n",
        "    out_device = cuda.device_array((rows, rows), dtype=np_type)\n",
        "\n",
        "    distance_matrix[grid_dim, block_dim](mat_device, out_device)\n",
        "\n",
        "    return out_device.copy_to_host()\n",
        "\n",
        "\n",
        "# Create a sample input matrix\n",
        "mat = np.array([[0, 1], [1, 0], [2, 2]], dtype=np.float32)\n",
        "\n",
        "# Compute the pairwise distance matrix\n",
        "dist_matrix = gpu_dist_matrix(mat, USE_64=False)\n",
        "\n",
        "# Print the result\n",
        "print(\"Input Matrix:\\n\", mat)\n",
        "print(\"Pairwise Distance Matrix:\\n\", dist_matrix)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gd3mpIgqudIf"
      },
      "source": [
        "# cuDF to accelerate dataframe operations using the GPU\n",
        "\n",
        "In this example, we will explore the use of [cuDF](https://github.com/rapidsai/cudf), a GPU DataFrame library, to perform data manipulation operations on a DataFrame. We will start by creating a DataFrame on the CPU using pandas, then transfer it to the GPU using cuDF. On the GPU, we will perform a series of operations, including column addition, conditional column creation, filtering, and grouping with aggregation. Finally, we will transfer the results back to the CPU and print the outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlTB0m2LoeXX",
        "outputId": "60b37bb4-44b5-47c5-dbb3-ab3a86cd77ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original DataFrame:\n",
            "    a   b    c\n",
            "0   1  10  100\n",
            "1   2  20  200\n",
            "2   2  25  250\n",
            "3   3  30  300\n",
            "4   3  35  350\n",
            "5   3  40  400\n",
            "6   4  45  450\n",
            "7   4  50  500\n",
            "8   5  55  550\n",
            "9   5  60  600\n",
            "10  5  65  650\n",
            "11  5  70  700\n",
            "\n",
            "DataFrame after operations on GPU:\n",
            "    a   b    c   d    e\n",
            "0   1  10  100  11    0\n",
            "1   2  20  200  22    0\n",
            "2   2  25  250  27    0\n",
            "3   3  30  300  33    0\n",
            "4   3  35  350  38    0\n",
            "5   3  40  400  43    0\n",
            "6   4  45  450  49  450\n",
            "7   4  50  500  54  500\n",
            "8   5  55  550  60  550\n",
            "9   5  60  600  65  600\n",
            "10  5  65  650  70  650\n",
            "11  5  70  700  75  700\n",
            "\n",
            "Filtered DataFrame:\n",
            "    a   b    c   d    e\n",
            "3   3  30  300  33    0\n",
            "4   3  35  350  38    0\n",
            "5   3  40  400  43    0\n",
            "6   4  45  450  49  450\n",
            "7   4  50  500  54  500\n",
            "8   5  55  550  60  550\n",
            "9   5  60  600  65  600\n",
            "10  5  65  650  70  650\n",
            "11  5  70  700  75  700\n",
            "\n",
            "Grouped and Aggregated DataFrame:\n",
            "   b_sum  b_mean  c_min  c_max  d_sum  d_count  e_mean      e_std\n",
            "a                                                                \n",
            "4     95    47.5    450    500    103        2   475.0  35.355339\n",
            "3    105    35.0    300    400    114        3     0.0   0.000000\n",
            "5    250    62.5    550    700    270        4   625.0  64.549722\n"
          ]
        }
      ],
      "source": [
        "import cudf\n",
        "import pandas as pd\n",
        "\n",
        "# Create a DataFrame on the CPU\n",
        "pdf = pd.DataFrame({\n",
        "    'a': [1, 2, 2, 3, 3, 3, 4, 4, 5, 5, 5, 5],\n",
        "    'b': [10, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70],\n",
        "    'c': [100, 200, 250, 300, 350, 400, 450, 500, 550, 600, 650, 700]\n",
        "})\n",
        "\n",
        "# Transfer it to the GPU\n",
        "gdf = cudf.DataFrame.from_pandas(pdf)\n",
        "\n",
        "# Perform operations on the GPU\n",
        "\n",
        "# Add two columns\n",
        "gdf['d'] = gdf['a'] + gdf['b']\n",
        "\n",
        "# Create a new column based on a condition\n",
        "gdf['e'] = gdf['c'] * (gdf['a'] > 3)\n",
        "\n",
        "# Filter rows based on a condition\n",
        "filtered_gdf = gdf[gdf['a'] > 2]\n",
        "\n",
        "# Group by column 'a' and aggregate\n",
        "grouped_gdf = filtered_gdf.groupby('a').agg({\n",
        "    'b': ['sum', 'mean'],\n",
        "    'c': ['min', 'max'],\n",
        "    'd': ['sum', 'count'],\n",
        "    'e': ['mean', 'std']\n",
        "})\n",
        "\n",
        "# Flatten the MultiIndex columns\n",
        "grouped_gdf.columns = ['_'.join(col) for col in grouped_gdf.columns]\n",
        "\n",
        "# Transfer the result back to the CPU\n",
        "result_pdf = grouped_gdf.to_pandas()\n",
        "\n",
        "# Print the results\n",
        "print(\"Original DataFrame:\")\n",
        "print(pdf)\n",
        "\n",
        "print(\"\\nDataFrame after operations on GPU:\")\n",
        "print(gdf)\n",
        "\n",
        "print(\"\\nFiltered DataFrame:\")\n",
        "print(filtered_gdf)\n",
        "\n",
        "print(\"\\nGrouped and Aggregated DataFrame:\")\n",
        "print(result_pdf)\n",
        "\n",
        "# Expected Results with Explanations:\n",
        "\n",
        "# Original DataFrame:\n",
        "#     a   b    c\n",
        "# 0   1  10  100\n",
        "# 1   2  20  200\n",
        "# 2   2  25  250\n",
        "# 3   3  30  300\n",
        "# 4   3  35  350\n",
        "# 5   3  40  400\n",
        "# 6   4  45  450\n",
        "# 7   4  50  500\n",
        "# 8   5  55  550\n",
        "# 9   5  60  600\n",
        "# 10  5  65  650\n",
        "# 11  5  70  700\n",
        "\n",
        "# DataFrame after operations on GPU:\n",
        "#     a   b    c   d    e\n",
        "# 0   1  10  100  11    0  (a + b = 11, c * (a > 3) = 0)\n",
        "# 1   2  20  200  22    0  (a + b = 22, c * (a > 3) = 0)\n",
        "# 2   2  25  250  27    0  (a + b = 27, c * (a > 3) = 0)\n",
        "# 3   3  30  300  33    0  (a + b = 33, c * (a > 3) = 0)\n",
        "# 4   3  35  350  38    0  (a + b = 38, c * (a > 3) = 0)\n",
        "# 5   3  40  400  43    0  (a + b = 43, c * (a > 3) = 0)\n",
        "# 6   4  45  450  49  450  (a + b = 49, c * (a > 3) = 450)\n",
        "# 7   4  50  500  54  500  (a + b = 54, c * (a > 3) = 500)\n",
        "# 8   5  55  550  60  550  (a + b = 60, c * (a > 3) = 550)\n",
        "# 9   5  60  600  65  600  (a + b = 65, c * (a > 3) = 600)\n",
        "# 10  5  65  650  70  650  (a + b = 70, c * (a > 3) = 650)\n",
        "# 11  5  70  700  75  700  (a + b = 75, c * (a > 3) = 700)\n",
        "\n",
        "# Filtered DataFrame:\n",
        "#     a   b    c   d    e\n",
        "# 3   3  30  300  33    0\n",
        "# 4   3  35  350  38    0\n",
        "# 5   3  40  400  43    0\n",
        "# 6   4  45  450  49  450\n",
        "# 7   4  50  500  54  500\n",
        "# 8   5  55  550  60  550\n",
        "# 9   5  60  600  65  600\n",
        "# 10  5  65  650  70  650\n",
        "# 11  5  70  700  75  700\n",
        "\n",
        "# Grouped and Aggregated DataFrame:\n",
        "#    b_sum  b_mean  c_min  c_max  d_sum  d_count  e_mean  e_std\n",
        "# a\n",
        "# 3    105    35.0    300    400    114        3     0.0    0.0\n",
        "# 4     95    47.5    450    500    103        2   475.0   35.4\n",
        "# 5    250    62.5    550    700    270        4   625.0   64.5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "711FiWYFope0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}